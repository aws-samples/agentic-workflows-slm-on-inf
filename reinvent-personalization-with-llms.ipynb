{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "359ef86573837a2a",
   "metadata": {},
   "source": [
    "# Let's Build Personalized Website using Agentic Workflows and Inferentia\n",
    "\n",
    "Notes: \n",
    "1. Use the native Jupyter Notebook to leverage the full features of this notebook\n",
    "2. Ensure you have Bedrock connection with access to Titan Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcac26309b11cf46",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1208d2cf05499b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T22:50:21.868106Z",
     "start_time": "2024-01-22T22:50:21.806873Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import base64\n",
    "import boto3\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import importlib\n",
    "import shutil\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import Bedrock\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.core.display import display, HTML\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cb554-a3ca-4eac-bcac-4196ab3f9fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Bedrock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325db3d1-363c-4e21-b217-b587c58dd804",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef3c4a-a9ee-4448-9fab-2f97250df81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch context from the response\n",
    "def get_contexts(retrievalResults):\n",
    "    total_text = \"\"\n",
    "    for result in retrievalResults.get(\"retrievalResults\", []):\n",
    "        content = result.get(\"content\", {})\n",
    "        text = content.get(\"text\", \"\")\n",
    "        # Remove the metadataAttributes content from the text\n",
    "        text = re.sub(r'\\{.*?metadataAttributes.*?\\}', '', text)\n",
    "        total_text += text\n",
    "    return total_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670a8e0-a6e2-44cc-883c-77dd31eafb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_profile(UserProfile):\n",
    "    profile = f\"Your customer is {UserProfile['Name']}, located in {UserProfile['Location']}. They are a {UserProfile['Industry']} company. Their mission statement is `{UserProfile['Mission']}.\"\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be33a6ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T22:47:57.456102Z",
     "start_time": "2024-01-22T22:47:57.408222Z"
    }
   },
   "source": [
    "### Declerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd02bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create general model inputs \n",
    "# do not edit any content in this section\n",
    "\n",
    "#image_modelId = 'amazon.titan-image-generator-v1'\n",
    "#model_id = {'Haiku': 'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "#           'Sonnet': 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "#           'StableDiff': 'stability.stable-diffusion-xl-v1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5e8cd-4807-4187-b57f-559b7e65238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENV VARIABLES\n",
    "kbId = '2TBRS1XZBR'\n",
    "model_llama3p1_endpoint = 'nous-research-Meta-Llama-3-8B-2024-09-23-19-42-59-162-endpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f050a-b4d4-44c6-aa84-f559b35afd3e",
   "metadata": {},
   "source": [
    "### Checking the endpoint status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791857f-6f0b-4d67-9562-c0ba259ed854",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2602b106-85ed-486e-8d36-29d854baaf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=model_llama3p1_endpoint)\n",
    "print(\"Status: \" + resp[\"EndpointStatus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0e831-0401-409c-84ff-2ca5658e2bc7",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6f7f32-d862-4687-abe2-2486ec44fc76",
   "metadata": {},
   "source": [
    "Offerings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ef5f1-df72-4df6-88af-e4bc59955c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./references/offerings.json\", \"r\") as file:\n",
    "    offerings = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa8e71-4ae4-46ce-9ffd-ba3d2841408f",
   "metadata": {},
   "source": [
    "User Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468c3de-9b13-4f72-a4a4-c47377d299e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Profiles = {\n",
    "    'Construction-Example': {\n",
    "        'Name': 'Example Corp Construction Inc',\n",
    "        'Industry': 'Construction',\n",
    "        'Location': 'New York City, NY',\n",
    "        'Mission': 'Building a sustainable future for New York'\n",
    "    },\n",
    "    'Manufacturing-Example': {\n",
    "        'Name': 'Example Corp Manuf LLC',\n",
    "        'Industry': 'Manufacturing',\n",
    "        'Location': 'San Jose, CA',\n",
    "        'Mission': 'Building the next generation Electric Vehicles'\n",
    "    },\n",
    "    'Mining-Example': {\n",
    "        'Name': 'Example Corp Mining Inc',\n",
    "        'Industry': 'Mining',\n",
    "        'Location': 'Bisbee, AZ',\n",
    "        'Mission': 'Extracting the value for America'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d03ef2-5010-4445-90c4-0f7b5f1be0ee",
   "metadata": {},
   "source": [
    "Now a user signs in (ITERATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544971ca-40c8-4795-9fcf-588dc1816ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITERATION - SELECTION:\n",
    "selected_profile = 'Manufacturing-Example'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f72bf-12fe-4231-b44d-4f4edccc9ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserProfile= Profiles[selected_profile]\n",
    "offering = re.sub(r'\\n#?', ' ', offerings[customer['Industry']])\n",
    "project = selected_profile + \"_Website_Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bd5fb1-a0ca-4ca3-b9a5-9e2117cc8cef",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ebf30-bbb3-4ac0-9b29-ced37cc10792",
   "metadata": {},
   "source": [
    "#### 1) Natural Language description of customer profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69555c15-b24c-402b-b454-f1e20140e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = UserProfile.copy()\n",
    "customer['Description'] = build_profile(UserProfile)\n",
    "print(customer['Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350661cc-f978-4b99-8bc0-6beb3fb2716e",
   "metadata": {},
   "source": [
    "#### 2) Retreieve painpoints of customer industry / any context\n",
    "This flow uses RAG to retreive documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab9a97-a2e1-44c6-a098-e7d70b367b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"{customer['Description']}\\nList the industry pain-points and challenges\"\n",
    "print(f\"Here is your customer:\\n{query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd820d5-2c23-4267-89b6-c704e282c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the context for the painpoints and challenges for this customer using RAG.\n",
    "context_painpoints = Bedrock.dec_retrieve(query, kbId, numberOfResults=5)\n",
    "contexts_painpoints = get_contexts(context_painpoints)\n",
    "contexts_painpoints = re.sub(r'\\n#?', ' ', contexts_painpoints)\n",
    "print(f\"These are the applicable pain-points/challenges:\\n{contexts_painpoints}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7f2ad0-765a-47ee-ab4b-5f77c869a5d1",
   "metadata": {},
   "source": [
    "### 3) Prompting AI to describe a website personalized for this profile and background\n",
    "Here the prompting is critical. Please see the guidance provided to the LLM. We also ask the response to be in two parts; 1/ Description, 2/ Visual Elements. The second part is needed for an easier traffic move to image generation or finding image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d5070d-2ccf-47eb-90ba-dd2a78815012",
   "metadata": {},
   "source": [
    "#### 3.1) Finding the possible painpoints using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42c5c0-44b0-472f-b955-36ad6c08f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an experienced business consultant in AnyCompany Consulting.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "*** AnyCompany Consulting Research Document ***\n",
    "{contexts_painpoints}\n",
    "*** End of AnyCompany Consulting Research Document ***\n",
    "\n",
    "\n",
    "Question: {customer['Description']} Based on the above research, list top-3 challenges for {customer['Name']}. Provide your list in bullet points without any preamble (e.g. \u2022 a pain-point, \u2022 another pain-point, etc.). \n",
    "\n",
    "\"\"\"\n",
    "params = {\"max_new_tokens\": 256, \"do_sample\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32bb5c2-e171-49b4-bd7d-75b1f9bdc303",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response_model = smr_client.invoke_endpoint(\n",
    "    EndpointName=model_llama3p1_endpoint,\n",
    "    Body=json.dumps({\"inputs\": prompt, \"parameters\": params}),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "response_painpoints = json.load(response_model['Body'])\n",
    "Top_pain_points_text= response_painpoints['generated_text'].split('<|eot_id|>')[0].replace('\\n',', ')\n",
    "print(f\"Raw Output - top painpoints:\\n{Top_pain_points}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17cab5-63e3-4032-adc6-e037f817fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this into a function\n",
    "Top_painpoints = Top_pain_points_text.replace(\"\u2022 \",\"\").split(',')\n",
    "Top_painpoints = [x.strip() for x in Top_painpoints]\n",
    "print(f\"Applicable painpoint labels found by LLMs:\\n{Top_painpoints}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2349b1-cca8-4f1c-8e7f-227dccbec480",
   "metadata": {},
   "source": [
    "#### 3.2) Finding the personalized offerings using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee3040-42b2-462c-a161-9b3ec34449e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are an experienced business consultant.\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "*** Offerings Document ***\n",
    "{offering}\n",
    "*** Offerings Document ***\n",
    "\n",
    "\n",
    "Question: {customer['Description']} Their top-3 painpoints are {Top_pain_points}.\n",
    "\n",
    "List and briefly advertise the top-3 offerings for {customer['Name']} based on the offerings document above.\n",
    "Provide your list in bullet points without any preamble (e.g. \u2022 an offering: short description, \u2022 an offering: short description, ...). \n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "\"\"\"\n",
    "params = {\"max_new_tokens\": 384, \"do_sample\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae77cc-1eaf-481c-803a-69462101102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response_model = smr_client.invoke_endpoint(\n",
    "    EndpointName=model_llama3p1_endpoint,\n",
    "    Body=json.dumps({\"inputs\": prompt, \"parameters\": params}),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "response_offerings = json.load(response_model['Body'])\n",
    "Top_offerings_text= response_offerings['generated_text'].split('<|eot_id|>')[0].replace('\\n',', ')\n",
    "print(f\"Raw Output - top offerings:\\n{Top_offerings_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f4006-0384-4dd7-bc55-1fac908c1500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this into a function\n",
    "pattern = r'\u2022\\s*(.*?):\\s*(.*?)\\.'\n",
    "\n",
    "matches = re.findall(pattern, Top_offerings_text)\n",
    "Top_offerings = [] #(label, description)\n",
    "for match in matches:\n",
    "    title = match[0]\n",
    "    description = match[1]\n",
    "    Top_offerings.append((title,description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4192c8-5248-459f-adb8-2bb2e90e8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Applicable offerings found and their advertisements created by LLMs:\\n\")\n",
    "[print(f\"{key}: {value}\\n\")for (key, value) in Top_offerings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64237857-24ba-4634-9aa8-791bd39dbd0c",
   "metadata": {},
   "source": [
    "#### 3.3) Art Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40257a52-26da-4c8f-b178-85d335ff4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "You are a UI/UX designer personalizing visual website content such as hero image and icons tailored to customer profile, personalized offerings and pain-points. \n",
    "Your task is to describe a hero image and six icons. For the Hero Image, design an attention-grabbing image that relates to the customer's industry, location, and mission. For icons, design simple, memorable icons that visually represent the concepts.\n",
    "\n",
    "Customer Profile:\n",
    "- Industry: {customer['Industry']}\n",
    "- Location: {customer['Location']}\n",
    "- Company Motto/Mission: {customer['Mission']}\n",
    "\n",
    "For the Hero Image:\n",
    "- Describe a scene that represents the customer's industry and mission\n",
    "- Include elements that reflect the customer location\n",
    "- Mention 1-2 key visual elements\n",
    "\n",
    "For each icon:\n",
    "- Describe a simple, easily recognizable shape or symbol\n",
    "- Mention one key visual element\n",
    "- Call our that this is an 'icon'.\n",
    "\n",
    "Each icon should be distinct yet part of a cohesive set in style and color.\n",
    "\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "Provide your response in the following structured format:\n",
    "\n",
    "** Hero Image[Description in 1-2 sentences]**\n",
    "** {Top_painpoints[0]} Icon [Description in one sentence]**\n",
    "** {Top_painpoints[1]} Icon [Description in one sentence]**\n",
    "** {Top_painpoints[2]} Icon [Description in one sentence]**\n",
    "** {Top_offerings[0][0]} Icon [Description in one sentence]**\n",
    "** {Top_offerings[1][0]} Icon [Description in one sentence]**\n",
    "** {Top_offerings[2][0]} Icon [Description in one sentence]**\n",
    "\n",
    "Provide your response using the exact format above, without any preamble.\n",
    "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "params = {\"max_new_tokens\": 512, \"do_sample\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55844632-04bc-4ee7-b54a-2b8ca2bd4fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response_model = smr_client.invoke_endpoint(\n",
    "    EndpointName=model_llama3p1_endpoint,\n",
    "    Body=json.dumps({\"inputs\": prompt, \"parameters\": params}),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "response_art= json.load(response_model['Body'])\n",
    "art_descriptions_text = response_art['generated_text'].split('<|eot_id|>')[0]\\\n",
    "                        .replace('\\n',', ').replace(', ,', '').replace('**,','**')\n",
    "print(f\"Raw Output - top offerings:\\n{art_descriptions_text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952d8e4-ff5d-4909-9333-6e1ca754bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the variable for the art descriptions that will help us to create a better prompt later\n",
    "art_descriptions = art_descriptions_text.split(\"**\")[1:]\n",
    "art_descriptions = {art_descriptions[i].strip():{\"Description\":art_descriptions[i+1].strip(), \\\n",
    "                    'FileName':art_descriptions[i].replace(' ','')+'.jpg'} for i in range(0,int(len(art_descriptions)),2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334da1cf-3a35-4ae1-b25f-f4c6a510de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Here is the art and their descriptions:\\n {json.dumps(art_descriptions, indent=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d7eaa5-3534-4b0e-9dfc-1683a5783a2b",
   "metadata": {},
   "source": [
    "#### 5) Image Creation based on Description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5cb25-c691-457c-be07-532579a75599",
   "metadata": {},
   "source": [
    "##### 5.1) Creating the imagery from the descriptions\n",
    "Notice that if the image is \"icon\" then 512 x 512 otherwise 1024 x 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f453a0f-74d0-4e61-8e11-c25e5150f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "responses_image = []\n",
    "images = []\n",
    "image_files = []\n",
    "for art, content in art_descriptions.items():\n",
    "    if 'Icon' in art:\n",
    "        art_height = 512\n",
    "        art_width = 512\n",
    "    else:\n",
    "        art_height = 1024\n",
    "        art_width = 1024\n",
    "        \n",
    "\n",
    "    response = Bedrock.invoke_stable_diff(prompt = content['Description'],  seed=0, height = art_height, \n",
    "                                          width = art_width)\n",
    "    responses_image.append(response)\n",
    "    image_bytes = base64.b64decode(response.encode('ascii'))\n",
    "    image_files.append(content['FileName'])\n",
    "\n",
    "    # Save the image\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    image.save(f\"{content['FileName']}\")\n",
    "    images.append(np.array(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae17de99-ea8c-4c87-8dfb-ead45b5ef69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of visual assets created: {}\".format(len(image_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fee76e-a943-45a8-a713-b42e9397a40a",
   "metadata": {},
   "source": [
    "##### b) Invoke Stable Diffusion\n",
    "Here we assumed that the image description is the prompt for Text-to-Image. We successively call the APIs and then save the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4843ea20-a727-47a6-ae04-8c1f95a47f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy(\"./references/anycompany_logo.jpg\", \"./anycompany_logo.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78a5af5-34f4-4f3c-bc87-bf567ed2c9bf",
   "metadata": {},
   "source": [
    "Let's plot the images generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cdd8f-a310-44a8-9816-d9cbd58d60b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the images\n",
    "fig, axs = plt.subplots(1, len(images), figsize=(30, 20))\n",
    "\n",
    "for i, (image, ax, filename) in enumerate(zip(images, axs, image_files)):\n",
    "    ax.imshow(image)\n",
    "    ax.set_title(filename, fontsize=16)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50077f-3e5b-41f8-90a9-e60e2f46d3c4",
   "metadata": {},
   "source": [
    "#### 6) Let's Generate our HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e49c09f-47da-4b48-a251-55963da574ec",
   "metadata": {},
   "source": [
    "First, we need to extract the response for the Section 1: Detailed Description from *response_personalized_website*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef97004-0756-47de-b8ad-246dbe1259a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Section-1 using regular expressions\n",
    "#section_1_pattern = r\"Section 1: Detailed Website Description\\n\\n(.*?)\\n\\nSection 2:\"\n",
    "#match = re.search(section_1_pattern, response_personalized_website, re.DOTALL)\n",
    "\n",
    "#if match:\n",
    "#    response_detailed_explanation = match.group(1)\n",
    "#    print(f\"Here is the Section-1 extracted from the LLM response:\\n\\n{response_detailed_explanation}\")\n",
    "#else:\n",
    "#    print(\"Section-1 not found in the input text.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee19b88a-06c4-460f-bd1a-55e07f513304",
   "metadata": {},
   "source": [
    "Here we will use Haiku to create the HTML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0b50b-1007-413a-8b02-ae62541648b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are an experienced front-end web developer specializing in creating accessible, responsive, and visually appealing websites. Your task is to generate the complete HTML, CSS, and JavaScript code that accurately implements the provided 'Website Description' while adhering to the specified guidelines.\n",
    "\n",
    "<website description>\n",
    "Know that, this your Design Guideline (Requirements):\n",
    "{design_guideline}\n",
    "\n",
    "You use the testimonials as follows;\n",
    "{testimonials}\n",
    "\n",
    "Website Description:\n",
    "{response_personalized_website}\n",
    "</website description>\n",
    "\n",
    "Please carefully read the 'Website Description' line by line, and then generate the HTML, CSS, and JavaScript code required to build the described website while following the specified design guidelines and requirements.\n",
    "\n",
    "Provide the HTML, CSS, and JavaScript code directly, starting with the <!DOCTYPE html> declaration, without any preamble or introduction.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a42f02-956d-4d01-854c-19d9d378c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response_html = Bedrock.invoke(prompt=prompt, modelID=model_id['Haiku'], max_tokens = 4096, temp = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d131a-0bb7-42de-831f-23d1953b7767",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "#print(response_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3130d5-c579-449c-873f-4d96c37bb2ef",
   "metadata": {},
   "source": [
    "#### Putting the assets into a single folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45657a3b-ac82-45de-8b82-8f755d255ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the folder for our project\n",
    "try:\n",
    "    os.mkdir(project)\n",
    "    print(f\"Project Folder: {project}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef9a122-b51d-4710-9c58-a30acaf8bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00768801-d471-4b85-b089-2b62a7afdcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('main.html', 'w', encoding='utf-8') as file:\n",
    "    file.write(response_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168e46a-a580-4c91-8fa5-24e7103e1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_files = list(visual_assets.keys())\n",
    "project_files.append('main.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a7dc3f-ce9d-45ac-a06d-9f4e02bbe868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in project_files:\n",
    "    destination = project + \"/\" + file\n",
    "    shutil.move(file, destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}