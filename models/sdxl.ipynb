{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1b5e70",
   "metadata": {},
   "source": [
    "# Deploy Stable Diffusion XL on AWS Inferentia2   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf46a1",
   "metadata": {},
   "source": [
    "In this notebook, we deploy a [Stable Diffusion XL](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) model using an Inferentia2 instance and optimum-neuron on Amazon SageMaker. [Optimum Neuron](https://huggingface.co/docs/optimum-neuron/en/index) is the interface betweeen the Transfomers library and AWS Purpose Built Accelerators - AWS Trainium and Inferentia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648579e",
   "metadata": {},
   "source": [
    "## Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f470ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet \"optimum-neuron\" \"sagemaker\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971797a",
   "metadata": {},
   "source": [
    "Note: you may need to restart the kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c1226",
   "metadata": {},
   "source": [
    "## Download and save the compiled model to a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddebd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    " \n",
    "# compiled model id\n",
    "compiled_model_id = \"aws-neuron/stable-diffusion-xl-base-1-0-1024x1024\"\n",
    " \n",
    "# save compiled model to local directory\n",
    "save_directory = \"/tmp/sdxl_neuron\"\n",
    "\n",
    "# Downloads our compiled model from the HuggingFace Hub\n",
    "# using the revision as neuron version reference\n",
    "# and makes sure we exlcude the symlink files and \"hidden\" files, like .DS_Store, .gitignore, etc.\n",
    "snapshot_download(compiled_model_id, revision=\"2.15.0\", local_dir=save_directory, local_dir_use_symlinks=False, allow_patterns=[\"[!.]*.*\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3575504",
   "metadata": {},
   "source": [
    "## Create `code` directory and `inference.py` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7a492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create code directory in our model directory\n",
    "!mkdir {save_directory}/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6809a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile {save_directory}/code/inference.py\n",
    "\n",
    "import os\n",
    "# Assign two neuron cores per worker\n",
    "os.environ[\"NEURON_RT_NUM_CORES\"] = \"2\"\n",
    "import torch\n",
    "import torch_neuronx\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from optimum.neuron import NeuronStableDiffusionXLPipeline\n",
    " \n",
    " \n",
    "def model_fn(model_dir):\n",
    "    # Load local converted model into pipeline\n",
    "    pipeline = NeuronStableDiffusionXLPipeline.from_pretrained(model_dir, device_ids=[0, 1])\n",
    "    return pipeline\n",
    " \n",
    " \n",
    "def predict_fn(data, pipeline):\n",
    "    # Extract prompt from data\n",
    "    prompt = data.pop(\"inputs\", data)\n",
    " \n",
    "    parameters = data.pop(\"parameters\", None)\n",
    " \n",
    "    if parameters is not None:\n",
    "        generated_images = pipeline(prompt, **parameters)[\"images\"]\n",
    "    else:\n",
    "        generated_images = pipeline(prompt)[\"images\"]\n",
    " \n",
    "    # Convert image into base64 string\n",
    "    encoded_images = []\n",
    "    for image in generated_images:\n",
    "        buffered = BytesIO()\n",
    "        image.save(buffered, format=\"JPEG\")\n",
    "        encoded_images.append(base64.b64encode(buffered.getvalue()).decode())\n",
    " \n",
    "    # Always return the first image\n",
    "    return {\"generated_images\": encoded_images}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f63e0f",
   "metadata": {},
   "source": [
    "## Configure SageMaker resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401dc6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# Create an Amazon Sagemaker session bucket for uploading data, models and logs\n",
    "# Amazon Sagemaker will automatically create this bucket if it does not exist\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # If a bucket name is not provided, set to default bucket\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    " \n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    " \n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    " \n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "assert sess.boto_region_name in [\"us-east-2\", \"us-east-1\"] , \"region must be us-east-2 or us-west-2, due to instance availability\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01272c",
   "metadata": {},
   "source": [
    "## Create a tar file (`model.tar.gz`) with model artifacts and scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1d396-8221-4e73-ad38-b0d4483f4a62",
   "metadata": {},
   "source": [
    "**Note to reviewer**: We are working on storing the `model.tar.gz` in a shared location to avoid this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bed63e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a model.tar.gz archive with all the model artifacts and the inference.py script.\n",
    "%cd {save_directory}\n",
    "!tar zcvf model.tar.gz *\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aeb0a7-ef64-4af2-9b8f-0a5621cda4b5",
   "metadata": {},
   "source": [
    "Creating the `model.tar.gz` takes around 10 minutes. If you are in a AWS event, your instructor will cover other aspects of the workshop as you wait for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7daa930",
   "metadata": {},
   "source": [
    "## Upload the tar file to a S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d2052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    " \n",
    "# Create s3 uri\n",
    "s3_model_path = f\"s3://{sess.default_bucket()}/neuronx/sdxl\"\n",
    " \n",
    "# Upload model.tar.gz\n",
    "s3_model_uri = S3Uploader.upload(local_path=f\"{save_directory}/model.tar.gz\", desired_s3_uri=s3_model_path)\n",
    "print(f\"model artifcats uploaded to {s3_model_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa70d29",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c391b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    " \n",
    "# Create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_uri,        # path to your model.tar.gz on s3\n",
    "   role=role,                      # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.34.1\",  # transformers version used\n",
    "   pytorch_version=\"1.13.1\",       # pytorch version used\n",
    "   py_version='py310',             # python version used\n",
    "   model_server_workers=1,         # number of workers for the model server\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c12b3d-ef57-4dcd-9e55-fa60aec74243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy the endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    endpoint_name=\"Stable-Diffusion-XL\",\n",
    "    initial_instance_count=1,      # number of instances\n",
    "    instance_type=\"ml.inf2.xlarge\", # AWS Inferentia Instance\n",
    "    volume_size = 128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a749977-b2b9-432d-8f9b-246b6596dbfc",
   "metadata": {},
   "source": [
    "**Note**: Ignore the \"Your model is not compiled. Please compile your model before using Inferentia.\" warning, we have already compiled our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f3453-7656-4e0b-8ee7-c0e9554ab61a",
   "metadata": {},
   "source": [
    "### The above step takes about 10-15 minutes.\n",
    "\n",
    "While you wait for the model to be deployed, you can read the below resources - \n",
    "- [AWS Neuron](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/index.html)\n",
    "- [AWS Inferentia2](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/neuron-hardware/inf2-arch.html)\n",
    "- [Amazon SageMaker Real Time Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)\n",
    "- [Amazon SageMaker with HuggingFace Optimum Neuron](https://huggingface.co/docs/optimum-neuron/en/guides/sagemaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05000ce0",
   "metadata": {},
   "source": [
    "## Invoke the model with a sample prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import base64\n",
    " \n",
    "# Helper decoder\n",
    "def decode_base64_image(image_string):\n",
    "  base64_image = base64.b64decode(image_string)\n",
    "  buffer = BytesIO(base64_image)\n",
    "  return Image.open(buffer)\n",
    " \n",
    "# Display PIL images as grid\n",
    "def display_image(image=None,width=500,height=500):\n",
    "    img = image.resize((width, height))\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06904515",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dog trying catch a flying pizza at a street corner, comic book, well lit, night time\"\n",
    " \n",
    "# Run prediction\n",
    "response = predictor.predict(data={\n",
    "  \"inputs\": prompt,\n",
    "  \"parameters\": {\n",
    "    \"num_inference_steps\" : 20,\n",
    "    \"negative_prompt\" : \"disfigured, ugly, deformed\"\n",
    "    }\n",
    "  }\n",
    ")\n",
    " \n",
    "# Decode and display image\n",
    "display_image(decode_base64_image(response[\"generated_images\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eeb729-f190-4e74-8ecb-b1c4bb3625fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "\n",
    "<b>DO NOT DELETE THE ENDPOINT</b>\n",
    "\n",
    "The endpoints will be used to invoke the models when building our application.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f41053",
   "metadata": {},
   "source": [
    "## Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49bbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}