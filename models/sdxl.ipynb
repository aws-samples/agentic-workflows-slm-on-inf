{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c1b5e70",
   "metadata": {},
   "source": [
    "# Deploy Stable Diffusion XL on AWS Inferentia2   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf46a1",
   "metadata": {},
   "source": [
    "In this notebook, we deploy a [Stable Diffusion XL](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0) model using an Inferentia2 instance and optimum-neuron on Amazon SageMaker. [Optimum Neuron](https://huggingface.co/docs/optimum-neuron/en/index) is the interface betweeen the Transfomers library and AWS Purpose Built Accelerators - AWS Trainium and Inferentia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648579e",
   "metadata": {},
   "source": [
    "## Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f470ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet \"sagemaker\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971797a",
   "metadata": {},
   "source": [
    "Note: you may need to restart the kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f63e0f",
   "metadata": {},
   "source": [
    "## Configure SageMaker resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401dc6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "# Create an Amazon Sagemaker session bucket for uploading data, models and logs\n",
    "# Amazon Sagemaker will automatically create this bucket if it does not exist\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # If a bucket name is not provided, set to default bucket\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    " \n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    " \n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    " \n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "assert sess.boto_region_name in [\"us-east-2\", \"us-east-1\"] , \"region must be us-east-2 or us-west-2, due to instance availability\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7daa930",
   "metadata": {},
   "source": [
    "## Store a `model.tar.gz` in a s3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d5ece-1f2b-4ff2-9991-7884ea131bff",
   "metadata": {},
   "source": [
    "We have pre-compiled the model, added an `inference` script, created a tar file and stored it in a s3 bucket.\n",
    "\n",
    "To read more about the detailed process, read [Deploy SDXL on AWS Inferentia2 with Amazon SageMaker](https://www.philschmid.de/inferentia2-stable-diffusion-xl) and the [developer documentation for deploying real time endpoints on sagemaker](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deploy-models.html#deploy-models-studio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf58ef-6dc1-47cd-9e65-61e8186efaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_model_uri = \"s3://sagemaker-examples-files-prod-us-east-2/models/neuron-sdxl-reinvent-2024/model.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa70d29",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c391b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    " \n",
    "# Create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_model_uri,        # path to your model.tar.gz on s3\n",
    "   role=role,                      # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.34.1\",  # transformers version used\n",
    "   pytorch_version=\"1.13.1\",       # pytorch version used\n",
    "   py_version='py310',             # python version used\n",
    "   model_server_workers=1,         # number of workers for the model server\n",
    ")\n",
    "huggingface_model._is_compiled_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c12b3d-ef57-4dcd-9e55-fa60aec74243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deploy the endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    endpoint_name=\"Stable-Diffusion-XL\",\n",
    "    initial_instance_count=1,      # number of instances\n",
    "    instance_type=\"ml.inf2.xlarge\", # AWS Inferentia Instance\n",
    "    volume_size = 128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4f3453-7656-4e0b-8ee7-c0e9554ab61a",
   "metadata": {},
   "source": [
    "### The above step takes about 10-15 minutes.\n",
    "\n",
    "While you wait for the model to be deployed, you can read the below resources - \n",
    "- [AWS Neuron](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/index.html)\n",
    "- [AWS Inferentia2](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/neuron-hardware/inf2-arch.html)\n",
    "- [Amazon SageMaker Real Time Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)\n",
    "- [Amazon SageMaker with HuggingFace Optimum Neuron](https://huggingface.co/docs/optimum-neuron/en/guides/sagemaker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05000ce0",
   "metadata": {},
   "source": [
    "## Invoke the model with a sample prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display\n",
    "import base64\n",
    " \n",
    "# Helper decoder\n",
    "def decode_base64_image(image_string):\n",
    "  base64_image = base64.b64decode(image_string)\n",
    "  buffer = BytesIO(base64_image)\n",
    "  return Image.open(buffer)\n",
    " \n",
    "# Display PIL images as grid\n",
    "def display_image(image=None,width=500,height=500):\n",
    "    img = image.resize((width, height))\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06904515",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dog trying to catch a flying pizza at a street corner, comic book, well lit, night time\"\n",
    " \n",
    "# Run prediction\n",
    "response = predictor.predict(data={\n",
    "  \"inputs\": prompt,\n",
    "  \"parameters\": {\n",
    "    \"num_inference_steps\" : 50,\n",
    "    \"negative_prompt\" : \"disfigured, ugly, deformed\"\n",
    "    }\n",
    "  }\n",
    ")\n",
    " \n",
    "# Decode and display image\n",
    "display_image(decode_base64_image(response[\"generated_images\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f1468f",
   "metadata": {},
   "source": [
    "If the above request times out, please retry and it should succeed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eeb729-f190-4e74-8ecb-b1c4bb3625fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"> \n",
    "\n",
    "<b>DO NOT DELETE THE ENDPOINT</b>\n",
    "\n",
    "The endpoints will be used to invoke the models when building our application.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f41053",
   "metadata": {},
   "source": [
    "## Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49bbdf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}